from google.cloud import bigquery
from google.cloud import bigquery_storage
import pandas as pd


def get_gbq_clients(project_id: str) -> (str, str):
    """
    Set credentials and get GBQ clients
    :param    project_id: project ID
    :return:  bqclient: Big Query Client
              bqstorageclient: Big Query Storage Client
    """
    # set the permutive credentials
    gbq_client = bigquery.Client(project=project_id)
    gbq_storage_client = bigquery_storage.BigQueryReadClient()
    # return authorized client connections
    return gbq_client, gbq_storage_client


def get_gbq_table(project_id: str, query_string: str) -> pd.DataFrame:
    """
    Get Table from SQL query in DataFrame format
    :param:   project_id: Project ID
              query_string: SQL select query
    :return:  dataframe with table from the GBQ generated by query_string
    """
    # initialize connection to GBQ
    gbq_client, gbq_storage_client = get_gbq_clients(project_id)
    return gbq_client.query(query_string).result().to_dataframe(bqstorage_client=gbq_storage_client)


def upload_table_to_gbq(project_id: str, df: pd.DataFrame, dataset: str, table: str,
                        method: str = 'append', schema=None) -> bool:
    """
    Upload DataFrame to GBQ table
    :param project_id: Project ID
    :param df: DataFrame to upload
    :param dataset: dataset where to upload the DataFrame in GBQ
    :param table: table where to upload the DataFrame in GBQ
    :param method: append or replace (default: append)
    :param schema: Table Schema (Default: None)
           Example: [bigquery.SchemaField("day", "DATE"),]
    :return: True if the dataframe is uploaded to GBQ
    """
    assert method in ('append', 'replace'), 'Method should be "append" or "replace"'
    gbq_client, _ = get_gbq_clients(project_id)
    # upload table to GBQ
    if method == 'replace':
        job_config = bigquery.LoadJobConfig(schema=schema, write_disposition='WRITE_TRUNCATE')
    else:
        job_config = bigquery.LoadJobConfig(schema=schema)
    job = gbq_client.load_table_from_dataframe(df, f'{dataset}.{table}', job_config=job_config)
    # Wait for the load job to complete.
    job.result()
    print(f'Table {dataset}.{table} is uploaded/updated to GBQ')
    return True


def delete_table_from_gbq(project_id: str, dataset: str, table: str) -> bool:
    """
    Delete table from GBQ
    :param project_id: Project ID
    :param dataset: dataset from which to delete the table
    :param table: table to delete
    :return: True if the table is deleted
    """
    gbq_client, _ = get_gbq_clients(project_id)
    # Deleting table from BQ
    table_ref = gbq_client.dataset(dataset).table(table)
    gbq_client.delete_table(table_ref)
    print(f'Table {table} is deleted from dataset {dataset} from BigQuery')
    return True
